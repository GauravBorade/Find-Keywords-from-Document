{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Keywords from the document\n",
    "In this notebook, we are going to extract the keywords from the document shared in the link.\n",
    "\n",
    "Original Document link is provided below.\n",
    "\n",
    "Link: http://bit.ly/epo_keyword_extraction_document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "# For basic string,text operation import following\n",
    "import re, string, unicodedata\n",
    "\n",
    "# Natural Language toolkit (nltk) used for text processing\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "#Importing necessary package for pdf to word conversion\n",
    "\n",
    "import os\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "# From PDFInterpreter import both PDFResourceManager and PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "# Import this to raise exception whenever text extraction from PDF is not allowed\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This is what we are trying to do:\n",
    "1) Transfer information from PDF file to PDF document object. This is done using parser\n",
    "2) Open the PDF file\n",
    "3) Parse the file using PDFParser object\n",
    "4) Assign the parsed content to PDFDocument object\n",
    "5) Now the information in this PDFDocumet object has to be processed. For this we need\n",
    "   PDFPageInterpreter, PDFDevice and PDFResourceManager\n",
    " 6) Finally process the file page by page \n",
    "'''\n",
    "#Put your pdf file path \n",
    "\n",
    "base_path = \"C:/Users/Dipti_B/Desktop/ds_keyword_assignment\"\n",
    "\n",
    "\n",
    "my_file = os.path.join(base_path + \"/\" + \"JavaBasics-notes.pdf\")\n",
    "log_file = os.path.join(base_path + \"/\" + \"JavaBasics-notes.txt\")\n",
    "\n",
    "password = \"\"\n",
    "extracted_text = \"\"\n",
    "\n",
    "# Open and read the pdf file in binary mode\n",
    "fp = open(my_file, \"rb\")\n",
    "\n",
    "# Create parser object to parse the pdf content\n",
    "parser = PDFParser(fp)\n",
    "\n",
    "# Store the parsed content in PDFDocument object\n",
    "document = PDFDocument(parser, password)\n",
    "\n",
    "# Check if document is extractable, if not abort\n",
    "if not document.is_extractable:\n",
    "\traise PDFTextExtractionNotAllowed\n",
    "\t\n",
    "# Create PDFResourceManager object that stores shared resources such as fonts or images\n",
    "rsrcmgr = PDFResourceManager()\n",
    "\n",
    "# set parameters for analysis\n",
    "laparams = LAParams()\n",
    "\n",
    "# Create a PDFDevice object which translates interpreted information into desired format\n",
    "# Device needs to be connected to resource manager to store shared resources\n",
    "# device = PDFDevice(rsrcmgr)\n",
    "# Extract the decive to page aggregator to get LT object elements\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "\n",
    "# Create interpreter object to process page content from PDFDocument\n",
    "# Interpreter needs to be connected to resource manager for shared resources and device \n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "# Ok now that we have everything to process a pdf document, lets process it page by page\n",
    "for page in PDFPage.create_pages(document):\n",
    "\t# As the interpreter processes the page stored in PDFDocument object\n",
    "\tinterpreter.process_page(page)\n",
    "\t# The device renders the layout from interpreter\n",
    "\tlayout = device.get_result()\n",
    "\t# Out of the many LT objects within layout, we are interested in LTTextBox and LTTextLine\n",
    "\tfor lt_obj in layout:\n",
    "\t\tif isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "\t\t\textracted_text += lt_obj.get_text()\n",
    "\t\t\t\n",
    "#close the pdf file\n",
    "fp.close()\n",
    "#print(extracted_text);\n",
    "raw=extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "Importing Data & Visualize it\n",
    "\n",
    "this step is importanat to get insight from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25550\n"
     ]
    }
   ],
   "source": [
    "#We can see the raw data\n",
    "#print(raw)\n",
    "print(len(raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "Preprocessing the data\n",
    "\n",
    "As we want to find keywords from data, first we have to clean it, filter it for further processing\n",
    "\n",
    "Here data is text so we have to remove white spaces, special characters, symbols, stopwords etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we have to find keywords we have to seperate out each word from whole document\n",
    "#this can be done by nltk's tokenize function\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5429\n"
     ]
    }
   ],
   "source": [
    "# So we have total 5331 tokens\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see the tokens data\n",
    "#print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from each word as we have to find keywords punctuation are treated as noise in data\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "#printing first 100 keywords hich are stored in stripped\n",
    "#print(stripped[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking whether the string consists of alphabetic characters only\n",
    "#if yes then only keeping it\n",
    "\n",
    "words=[word for word in stripped if word.isalpha()]\n",
    "#print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing length of punctioctions free words\n",
    "#So we are filtering unwanted stuff \n",
    "#print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all characters to loer case for further processing\n",
    "#This is also called as normelization\n",
    "\n",
    "words_lower=[w.lower() for w in words]\n",
    "#print(words_lower[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "# we can see the list of stop words by printing it\n",
    "stop_words = stopwords.words('english')\n",
    "#print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering stop words\n",
    "set(stopwords.words('english'))\n",
    "words_stopw_rem = [w for w in words_lower if not w in stop_words]\n",
    "#print(words_stopw_rem[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing length of words after removing stop words\n",
    "#print(len(words_stopw_rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemitizing is the  process of converting the words of a sentence to its dictionary form. \n",
    "#it is very important as it normalize all words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_lemmatized=[lemmatizer.lemmatize(word)for word in words_stopw_rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(words_lemmatized))\n",
    "#print(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zeroextend',\n",
       " 'yet',\n",
       " 'yet',\n",
       " 'www',\n",
       " 'www',\n",
       " 'www',\n",
       " 'www',\n",
       " 'written',\n",
       " 'written',\n",
       " 'write',\n",
       " 'write',\n",
       " 'write',\n",
       " 'write',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'world',\n",
       " 'world',\n",
       " 'within',\n",
       " 'within',\n",
       " 'within',\n",
       " 'windowmanager',\n",
       " 'window',\n",
       " 'window',\n",
       " 'widthw',\n",
       " 'width',\n",
       " 'width',\n",
       " 'width',\n",
       " 'width',\n",
       " 'wide',\n",
       " 'wide',\n",
       " 'whenever',\n",
       " 'well',\n",
       " 'web',\n",
       " 'web',\n",
       " 'way',\n",
       " 'way',\n",
       " 'vspace',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'void',\n",
       " 'visible',\n",
       " 'virus',\n",
       " 'virtually',\n",
       " 'view',\n",
       " 'via',\n",
       " 'version',\n",
       " 'version',\n",
       " 'version',\n",
       " 'version',\n",
       " 'vector',\n",
       " 'vector',\n",
       " 'variablename',\n",
       " 'variablename',\n",
       " 'variablelength',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'variable',\n",
       " 'valuev',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'value',\n",
       " 'valid',\n",
       " 'v',\n",
       " 'using',\n",
       " 'using',\n",
       " 'using',\n",
       " 'using',\n",
       " 'using',\n",
       " 'userdefined',\n",
       " 'useful',\n",
       " 'used',\n",
       " 'used',\n",
       " 'used',\n",
       " 'used',\n",
       " 'used',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'us',\n",
       " 'upperleft',\n",
       " 'unnecessarily',\n",
       " 'unlike',\n",
       " 'unlike',\n",
       " 'unit',\n",
       " 'unit',\n",
       " 'unicode',\n",
       " 'unicode',\n",
       " 'undefined',\n",
       " 'typename',\n",
       " 'typename',\n",
       " 'typename',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'type',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'try',\n",
       " 'truefalse',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'trivialapplicationclass',\n",
       " 'trivialapplication',\n",
       " 'trivialapplication',\n",
       " 'trivialapplet',\n",
       " 'trivialapplet',\n",
       " 'trivial',\n",
       " 'treated',\n",
       " 'translates',\n",
       " 'translated',\n",
       " 'tostring',\n",
       " 'topic',\n",
       " 'together',\n",
       " 'time',\n",
       " 'time',\n",
       " 'three',\n",
       " 'thread',\n",
       " 'thread',\n",
       " 'thread',\n",
       " 'thread',\n",
       " 'thread',\n",
       " 'thread',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'therefore',\n",
       " 'therefore',\n",
       " 'therefore',\n",
       " 'therefore',\n",
       " 'thereby',\n",
       " 'text',\n",
       " 'text',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'terminates',\n",
       " 'terence',\n",
       " 'ten',\n",
       " 'tell',\n",
       " 'tedious',\n",
       " 'task',\n",
       " 'task',\n",
       " 'take',\n",
       " 'tag',\n",
       " 'tag',\n",
       " 'tag',\n",
       " 'tag',\n",
       " 'table',\n",
       " 'systemoutprintln',\n",
       " 'systemoutprintln',\n",
       " 'systemoutprintln',\n",
       " 'systemoutprintln',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'system',\n",
       " 'syntax',\n",
       " 'syntax',\n",
       " 'symbol',\n",
       " 'switch',\n",
       " 'switch',\n",
       " 'suspend',\n",
       " 'suspend',\n",
       " 'surrounding',\n",
       " 'superdispose',\n",
       " 'superclone',\n",
       " 'superclass',\n",
       " 'super',\n",
       " 'suffix',\n",
       " 'suffix',\n",
       " 'subclass',\n",
       " 'subclass',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'structure',\n",
       " 'structure',\n",
       " 'structure',\n",
       " 'structs',\n",
       " 'struct',\n",
       " 'stringvalueof',\n",
       " 'stringbuffer',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'storing',\n",
       " 'stored',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'still',\n",
       " 'stats',\n",
       " 'static',\n",
       " 'static',\n",
       " 'static',\n",
       " 'static',\n",
       " 'static',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'statement',\n",
       " 'state',\n",
       " 'state',\n",
       " 'stat',\n",
       " 'stat',\n",
       " 'startingclassnamemain',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'start',\n",
       " 'standard',\n",
       " 'standard',\n",
       " 'standalone',\n",
       " 'stale',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'stack',\n",
       " 'square',\n",
       " 'spush',\n",
       " 'specify',\n",
       " 'specify',\n",
       " 'specified',\n",
       " 'specifically',\n",
       " 'specific',\n",
       " 'space',\n",
       " 'space',\n",
       " 'source',\n",
       " 'source',\n",
       " 'source',\n",
       " 'source',\n",
       " 'source',\n",
       " 'something',\n",
       " 'software',\n",
       " 'socket',\n",
       " 'socket',\n",
       " 'sizeof',\n",
       " 'sizeof',\n",
       " 'sizeof',\n",
       " 'sizeof',\n",
       " 'sizeof',\n",
       " 'sizeof',\n",
       " 'size',\n",
       " 'size',\n",
       " 'singleline',\n",
       " 'simply',\n",
       " 'simply',\n",
       " 'simple',\n",
       " 'simple',\n",
       " 'simple',\n",
       " 'simple',\n",
       " 'similar',\n",
       " 'similar',\n",
       " 'similar',\n",
       " 'similar',\n",
       " 'similar',\n",
       " 'signed',\n",
       " 'signature',\n",
       " 'show',\n",
       " 'show',\n",
       " 'show',\n",
       " 'short',\n",
       " 'shallow',\n",
       " 'several',\n",
       " 'settitle',\n",
       " 'settitle',\n",
       " 'set',\n",
       " 'set',\n",
       " 'serve',\n",
       " 'sequence',\n",
       " 'separate',\n",
       " 'sends',\n",
       " 'semantics',\n",
       " 'semantics',\n",
       " 'semantics',\n",
       " 'semantics',\n",
       " 'semantics',\n",
       " 'semantics',\n",
       " 'security',\n",
       " 'secure',\n",
       " 'secure',\n",
       " 'section',\n",
       " 'section',\n",
       " 'section',\n",
       " 'second',\n",
       " 'second',\n",
       " 'search',\n",
       " 'scrollbars',\n",
       " 'scoped',\n",
       " 'say',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'runtime',\n",
       " 'running',\n",
       " 'run',\n",
       " 'run',\n",
       " 'robustness',\n",
       " 'robust',\n",
       " 'robust',\n",
       " 'rightshift',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'rewrite',\n",
       " 'revisited',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'return',\n",
       " 'result',\n",
       " 'restriction',\n",
       " 'respond',\n",
       " 'resource',\n",
       " 'resource',\n",
       " 'resource',\n",
       " 'reside',\n",
       " 'reside',\n",
       " 'reside',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserved',\n",
       " 'reserve',\n",
       " 'requires',\n",
       " 'representation',\n",
       " 'removed',\n",
       " 'remove',\n",
       " 'remains',\n",
       " 'relieving',\n",
       " 'related',\n",
       " 'referring',\n",
       " 'referred',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'reference',\n",
       " 'refer',\n",
       " 'refer',\n",
       " 'refer',\n",
       " 'refer',\n",
       " 'refer',\n",
       " 'refer',\n",
       " 'reduces',\n",
       " 'redrawn',\n",
       " 'real',\n",
       " 'quitting',\n",
       " 'quit',\n",
       " 'quit',\n",
       " 'quit',\n",
       " 'qualifiedid',\n",
       " 'put',\n",
       " 'push',\n",
       " 'push',\n",
       " 'purely',\n",
       " 'publicly',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'public',\n",
       " 'provided',\n",
       " 'proper',\n",
       " 'programming',\n",
       " 'programming',\n",
       " 'programming',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'processed',\n",
       " 'problem',\n",
       " 'priority',\n",
       " 'print',\n",
       " 'print',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'primitive',\n",
       " 'pretend',\n",
       " 'present',\n",
       " 'preexisting',\n",
       " 'predefined',\n",
       " 'predefined',\n",
       " 'predefined',\n",
       " 'predefined',\n",
       " 'predefined',\n",
       " 'precedence',\n",
       " 'preceded',\n",
       " 'potential',\n",
       " 'portion',\n",
       " 'portable',\n",
       " 'portable',\n",
       " 'portable',\n",
       " 'portable',\n",
       " 'portable',\n",
       " 'portability',\n",
       " 'portability',\n",
       " 'port',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointer',\n",
       " 'pointed',\n",
       " 'point',\n",
       " 'point',\n",
       " 'point',\n",
       " 'point',\n",
       " 'point',\n",
       " 'plus',\n",
       " 'platform',\n",
       " 'platform',\n",
       " 'platform',\n",
       " 'platform',\n",
       " 'platform',\n",
       " 'placed',\n",
       " 'placed',\n",
       " 'place',\n",
       " 'place',\n",
       " 'phase',\n",
       " 'performs',\n",
       " 'perform',\n",
       " 'pc',\n",
       " 'passed',\n",
       " 'passed',\n",
       " 'passed',\n",
       " 'passed',\n",
       " 'passed',\n",
       " 'particular',\n",
       " 'particular',\n",
       " 'part',\n",
       " 'part',\n",
       " 'paramtest',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'parameter',\n",
       " 'param',\n",
       " 'param',\n",
       " 'param',\n",
       " 'painting',\n",
       " 'paint',\n",
       " 'paint',\n",
       " 'paint',\n",
       " 'page',\n",
       " 'packageobj',\n",
       " 'package',\n",
       " 'p',\n",
       " 'owner',\n",
       " 'override',\n",
       " 'outside',\n",
       " 'output',\n",
       " 'output',\n",
       " 'output',\n",
       " 'order',\n",
       " 'optionally',\n",
       " 'optional',\n",
       " 'optional',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operator',\n",
       " 'operation',\n",
       " 'operating',\n",
       " 'opening',\n",
       " 'opening',\n",
       " 'onetwo',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'old',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'often',\n",
       " 'octal',\n",
       " 'obtained',\n",
       " 'observation',\n",
       " 'objmethod',\n",
       " 'objmember',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'object',\n",
       " 'number',\n",
       " 'nullterminated',\n",
       " 'nullpointerexception',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'nt',\n",
       " 'nt',\n",
       " 'nt',\n",
       " 'npackageclass',\n",
       " 'notice',\n",
       " 'nothing',\n",
       " 'nothing',\n",
       " 'nothing',\n",
       " 'note',\n",
       " 'note',\n",
       " 'note',\n",
       " 'note',\n",
       " 'note',\n",
       " 'note',\n",
       " 'normal',\n",
       " 'nonpublic',\n",
       " 'nonportable',\n",
       " 'next',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'new',\n",
       " 'netscape',\n",
       " 'nested',\n",
       " 'needed',\n",
       " 'need',\n",
       " 'need',\n",
       " 'need',\n",
       " 'need',\n",
       " 'need',\n",
       " 'necessary',\n",
       " 'navigator',\n",
       " 'native',\n",
       " 'namen',\n",
       " 'namelist',\n",
       " 'namelist',\n",
       " 'named',\n",
       " 'must',\n",
       " 'must',\n",
       " 'must',\n",
       " 'must',\n",
       " 'multiple',\n",
       " 'multidimensional',\n",
       " 'much',\n",
       " 'modified',\n",
       " 'mml',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'method',\n",
       " 'message',\n",
       " 'message',\n",
       " 'message',\n",
       " 'menu',\n",
       " 'menu',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'memory',\n",
       " 'member',\n",
       " 'mean',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'market',\n",
       " 'many',\n",
       " 'mandatory',\n",
       " 'making',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'major',\n",
       " 'main',\n",
       " 'main',\n",
       " 'main',\n",
       " 'main',\n",
       " 'main',\n",
       " 'main',\n",
       " 'machineindependent',\n",
       " 'machine',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(set(words_lemmatized)))\n",
    "sorted((words_lemmatized),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:\n",
    "    \n",
    "Getting insight from data\n",
    "\n",
    "All preprocessing task has done now we can play with this data to find the keywords, which is our final goal\n",
    "\n",
    "we can also calculate lexical richness of the text\n",
    "\n",
    "importance or how frequent the specific word has used\n",
    "\n",
    "count of each word in this document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.536082474226806"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's calculate a measure of the lexical richness of the text\n",
    "# From this we can say that in document most of the words are repeated as result shows it has 28.9% lexical richness\n",
    "len(set(words_lemmatized))*100 / len(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.154639175257732"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word\n",
    "#ex: java\n",
    "100 * words_lemmatized.count('java') / len(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freqDist = nltk.FreqDist(words_lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java:125\n",
      "object:53\n",
      "new:52\n",
      "basic:48\n",
      "button:48\n",
      "data:43\n",
      "applet:41\n",
      "int:40\n",
      "code:38\n",
      "c:38\n",
      "method:37\n",
      "array:33\n",
      "b:33\n",
      "class:32\n",
      "string:28\n",
      "jgurucom:23\n",
      "right:23\n",
      "reserved:23\n",
      "example:22\n",
      "public:22\n",
      "type:22\n",
      "program:20\n",
      "comment:18\n",
      "pointer:17\n",
      "cc:16\n",
      "return:16\n",
      "language:15\n",
      "use:15\n",
      "memory:15\n",
      "null:15\n",
      "void:14\n",
      "primitive:14\n",
      "make:13\n",
      "operator:13\n",
      "application:12\n",
      "browser:12\n",
      "may:12\n",
      "reference:12\n",
      "element:12\n",
      "garbage:11\n",
      "allocate:11\n",
      "system:10\n",
      "runtime:10\n",
      "file:10\n",
      "variable:10\n",
      "following:10\n",
      "parameter:10\n",
      "stack:10\n",
      "would:10\n",
      "constant:10\n"
     ]
    }
   ],
   "source": [
    "# Output top 50 words\n",
    "#It shows how much time that perticular word has repeated in document\n",
    "\n",
    "for word, frequency in words_freqDist.most_common(50):\n",
    "    print(u'{}:{}'.format(word, frequency))\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:\n",
    "\n",
    "This is the final step\n",
    "\n",
    "After finding the occurrence of each word now we can find the weight of each word\n",
    "\n",
    "Here the document is related to Java language\n",
    "\n",
    "so constraining the word length will remove 'c' which is itself a language\n",
    "\n",
    "so printing the keywords according to their weights and saving the same in CSV format\n",
    "\n",
    "this CSV file is stored in the same folder in which this notebook is saved\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'java': 125, 'object': 53, 'new': 52, 'basic': 48, 'button': 48, 'data': 43, 'applet': 41, 'int': 40, 'code': 38, 'c': 38, ...})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving output in csv file\n",
    "#for this we require pandas package and collection package to deal with freqDist output\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "d=words_freqDist\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(d,orient='index').reset_index()\n",
    "df_new=df\n",
    "#df_new.columns=['index','Keywords']\n",
    "df_new.sort_values(by='index',ascending=True)\n",
    "df_new.columns=['index','Keywords']\n",
    "f=df_new\n",
    "f.sort_values(by='Keywords',ascending=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           index  Keywords\n",
      "0           java      5.15\n",
      "164       object      2.19\n",
      "454          new      2.14\n",
      "275       button      1.98\n",
      "1          basic      1.98\n",
      "109         data      1.77\n",
      "11        applet      1.69\n",
      "429          int      1.65\n",
      "85          code      1.57\n",
      "387            c      1.57\n",
      "134       method      1.53\n",
      "218            b      1.36\n",
      "121        array      1.36\n",
      "69         class      1.32\n",
      "51        string      1.15\n",
      "68      reserved      0.95\n",
      "66      jgurucom      0.95\n",
      "67         right      0.95\n",
      "80       example      0.91\n",
      "424         type      0.91\n",
      "216       public      0.91\n",
      "6        program      0.82\n",
      "17       comment      0.74\n",
      "119      pointer      0.70\n",
      "384       return      0.66\n",
      "59            cc      0.66\n",
      "458         null      0.62\n",
      "450       memory      0.62\n",
      "15      language      0.62\n",
      "73           use      0.62\n",
      "..           ...       ...\n",
      "375          alt      0.04\n",
      "374     codebase      0.04\n",
      "373    mandatory      0.04\n",
      "372       height      0.04\n",
      "396   singleline      0.04\n",
      "168      initial      0.04\n",
      "158     together      0.04\n",
      "399       useful      0.04\n",
      "160       member      0.04\n",
      "420      leading      0.04\n",
      "419     multiple      0.04\n",
      "165         come      0.04\n",
      "166       flavor      0.04\n",
      "415     generate      0.04\n",
      "414      javadoc      0.04\n",
      "413    processed      0.04\n",
      "167   standalone      0.04\n",
      "411         also      0.04\n",
      "410   commenting      0.04\n",
      "409      reserve      0.04\n",
      "408   commentary      0.04\n",
      "407       normal      0.04\n",
      "406          try      0.04\n",
      "405  surrounding      0.04\n",
      "404  observation      0.04\n",
      "403  interesting      0.04\n",
      "402         lead      0.04\n",
      "401       nested      0.04\n",
      "400  combination      0.04\n",
      "691        blank      0.04\n",
      "\n",
      "[692 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "f['Keywords']=round((f['Keywords']*100)/len(words_lemmatized),2)\n",
    "\n",
    "print(f)\n",
    "#Saving it in csv format\n",
    "\n",
    "f.to_csv(\"keywords_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
